{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f372cd1-0d04-4d06-8e33-2130fbf420a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "from tensorflow import keras\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c346a712-70e4-4dd9-acb4-cc97e1c5e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51af9d17-c0ce-4652-b58e-36840fead06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "#SIM=\"/gpfs/slac/atlas/fs1/d/rafaeltl/public/Muon/simulation/20220912/SIG_atlas_nsw_pad_z0_xya/\"\n",
    "DATA_LOC=config.DATA_LOC_VALIDATE\n",
    "\n",
    "files=glob(f\"{DATA_LOC}\")\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef14217-e779-452e-b144-b8516924e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"../models/MyTCN_CL4.3.1.0..4.3.3.0_DL20_CBNormFalse_DBNormFalse_IBNormFalse_penTrue_ptype0_regBiasTrue_lrate0.001_Flatten_L1R0.0005_DetMat_pc02_4Outputs_LONG_run22\"\n",
    "model = keras.models.load_model(model_name,compile=False)\n",
    "np.save(\"exported_weights.npy\",model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2c10ff-1275-4c94-843c-b1142d54f36b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Functional in module tensorflow.python.keras.engine.functional object:\n",
      "\n",
      "class Functional(tensorflow.python.keras.engine.training.Model)\n",
      " |  Functional(*args, **kwargs)\n",
      " |  \n",
      " |  A `Functional` model is a `Model` defined as a directed graph of layers.\n",
      " |  \n",
      " |  Three types of `Model` exist: subclassed `Model`, `Functional` model,\n",
      " |  and `Sequential` (a special case of `Functional`).\n",
      " |  In general, more Keras features are supported with `Functional`\n",
      " |  than with subclassed `Model`s, specifically:\n",
      " |  \n",
      " |  - Model cloning (`keras.models.clone`)\n",
      " |  - Serialization (`model.get_config()/from_config`, `model.to_json()/to_yaml()`\n",
      " |  - Whole-model saving (`model.save()`)\n",
      " |  \n",
      " |  A `Functional` model can be instantiated by passing two arguments to\n",
      " |  `__init__`. The first argument is the `keras.Input` Tensors that represent\n",
      " |  the inputs to the model. The second argument specifies the output\n",
      " |  tensors that represent the outputs of this model. Both arguments can be a\n",
      " |  nested structure of tensors.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```\n",
      " |  inputs = {'x1': keras.Input(shape=(10,)), 'x2': keras.Input(shape=(1,))}\n",
      " |  t = keras.layers.Dense(1, activation='relu')(inputs['x1'])\n",
      " |  outputs = keras.layers.Add()([t, inputs['x2'])\n",
      " |  model = keras.Model(inputs, outputs)\n",
      " |  ```\n",
      " |  \n",
      " |  A `Functional` model constructed using the Functional API can also include raw\n",
      " |  TensorFlow functions, with the exception of functions that create Variables\n",
      " |  or assign ops.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```\n",
      " |  inputs = keras.Input(shape=(10,))\n",
      " |  x = keras.layers.Dense(1)(inputs)\n",
      " |  outputs = tf.nn.relu(x)\n",
      " |  model = keras.Model(inputs, outputs)\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    inputs: List of input tensors (must be created via `tf.keras.Input()`).\n",
      " |    outputs: List of outputs tensors.\n",
      " |    name: String, optional. Name of the model.\n",
      " |    trainable: Boolean, whether the model's variables should be trainable.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Functional\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, inputs=None, outputs=None, name=None, trainable=True)\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`.\n",
      " |          **kwargs: Any additional arguments. Supported arguments:\n",
      " |              - `experimental_steps_per_execution`: Int. The number of batches to\n",
      " |                run during each `tf.function` call. Running multiple batches\n",
      " |                inside a single `tf.function` call can greatly improve performance\n",
      " |                on TPUs or small models with a large Python overhead. Note that if\n",
      " |                this value is set to `N`, `Callback.on_batch` methods will only be\n",
      " |                called every `N` batches. This currently defaults to `1`. At most,\n",
      " |                one full epoch will be run each execution. If a number larger than\n",
      " |                the size of the epoch is passed, the execution will be truncated\n",
      " |                to the size of the epoch.\n",
      " |              - `sample_weight_mode` for backward compatibility.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.evaluate, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropuout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.fit, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.predict, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |      \n",
      " |      - The model architecture, allowing to re-instantiate the model.\n",
      " |      - The model weights.\n",
      " |      - The state of the optimizer, allowing to resume training\n",
      " |          exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model` is a compiled model ready to be used\n",
      " |      (unless the saved model was never compiled in the first place).\n",
      " |      \n",
      " |      Models built with the Sequential and Functional API can be saved to both the\n",
      " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
      " |      SavedModel format.\n",
      " |      \n",
      " |      Note that the model weights may have different scoped names after being\n",
      " |      loaded. Scoped names include the model/layer names, such as\n",
      " |      `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
      " |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |              options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathemetical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = metrics_module.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(math_ops.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.losses` instead.\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.updates` instead.\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |      Dtype used by the weights of the layer, set in the constructor.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor 'Abs:0' shape=() dtype=float32>]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |      DEPRECATED FUNCTION\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8295f233-7e76-45a2-9175-b719d4ca0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load(f'/afs/cern.ch/user/r/rrojas/public/ML/r-dev-branch/si-mu-lator/hls4ml/Y_test_50000_detMat_atlas_nsw_pad_z0.npy')\n",
    "x_test = np.load(f'/afs/cern.ch/user/r/rrojas/public/ML/r-dev-branch/si-mu-lator/hls4ml/X_test_50000_detMat_atlas_nsw_pad_z0.npy')\n",
    "weights = np.load(f'exported_weights.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5708203-4c09-4fde-b820-e90a92210b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAGiCAYAAAA4KgmiAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVRV9fo/8PdRGc9hCkLGJRKleWXSckILpzIjwABBjRsiKCmJIgmUJiqKU+jlXleEXTNpyTHI8AYK4i2vICeu9/s1h6uZ5BAYYCCzDCKf3x/+2F8O45n2OQd9XmuxFnv67M8+eh72/uxnP1vAGGMghBD+SIZpugeEkCcfBRpCCO9GdJ84cOAAGhsbNdUXQsgT4oUXXoCXlxc3LXVGs3nzZrV3iGi/L7/8Erdv39Z0N9Tm9u3b+PLLLzXdjSHrzp07vT6/ET1Xio6OVluHyNAgkUiwaNEiTJ06VdNdUQuJRIKKigr6LihIIpEgOTlZah6N0RBCeEeBhhDCOwo0hChAX18fAoEAnp6eUvNLS0vx8ccfa6ZTKlJZWYn4+Hi0trZy86qrqyEQCCAQCBAUFCR3mxRoCC9CQkJw/Phxte3Py8sLhw4dUtv+AODatWs4c+YMN11fX4/g4GBERUUBADo7O5GSkgJHR0eYmprCz88PVVVVg7bLGEN6ejrGjh0LAwMDuLm54cSJE1LrtLS04N1334VQKISdnR2++OILufo+YsQILnB0/cydOxcAYGVlhUmTJmH16tXc+hYWFmCMISkpSa79dKFAQ3hx6NAh+Pj4aLobapWSkoK5c+fC3NwcAHDp0iUkJSUhJycHpaWlaGlpkfry9ufOnTtISUlBfn4+ampqEBwcjLfffhvl5eXcOps3b8avv/6K0tJSHD58GO+//z4uX74sc199fX3BGON+tm/fjoCAAG75ggULUFRUhKtXr8rxCfSPAg1RuTVr1kAgECAmJkZqOjIyEj4+PhCJRPD398ejR48AAEFBQdz6np6eEIlEWLBgAerq6gAA/v7+EAgE3BmLp6cnBAIBTp8+zW2fm5uLpUuXQiAQIDU1Vf0HDeCbb77BtGnTpOaFh4dj3LhxsLCwwJw5c3Djxo1B23FwcMD58+cxatQoGBoaYt26ddDR0cGVK1cAPD5T+vzzz7Fx40ZYW1tj1qxZ8PHxwYEDB2Tua1paGvd7Z2cnjh49isWLF0ut4+HhgczMTJnbHEiv29uEKGvfvn3Q19dHR0eH1HRmZiays7Oxf/9+vPzyyygoKMC8efMgFoshEomQnZ2N7OxsWFpaIiAgAOvXr0daWhqysrKkkr/OnDkDNzc3blosFqOpqQn+/v4ICQlR9+FySktLMXLkSG7azc0Nbm5uaGtrQ15eHnbv3o3Q0FC5221oaABjDBMmTAAAVFVVoaamBs7Oztw6Li4uKCgokLnNZ555hvs9Ly8P06ZNg0gkklrHysoKpaWlcve3L3RGQ9TmlVdegbOzM+zs7DBp0iTcvHlTarmvry/Gjx8PS0tLREdHQywWK7W/mJgYLF++XKk2ZPXw4UM0NzfD0NCw17K9e/ciIiICy5cvR0JCgtxt79y5EwkJCbC0tATweGAWAIyNjbl1jI2N8ccffyjU99TUVERERPSaLxQKcf/+fYXa7InOaIjadI1dAICBgQHa29v7XW5tbY3GxkY0NzdDKBQqtL/Ozk6oqziBjo4OhEIhHjx40OfyjIyMXneoZHHw4EHU1tZi27Zt3DwLCwsAj890us5CGhoa8Oyzz8rdfllZGerr6+Hi4tJrWXNzs9SZjzIo0BCt0f2OTEVFBYyMjLggo6uri5aWFm5511/1LgKBoFd7PbNT+ebk5NTnXaW4uDiF2vvyyy9RUlLSa8xp5MiRMDc3x5UrV2BjYwPg8cDzuHHj5N5HWloawsPD+1xWWVkJJycn+TveB7p0IlrjxIkTuHTpEu7du4fk5GSpfA1HR0fk5eWhqakJR44c6fXwr5mZGW7duoXvv/8eixYtAqDeSycA8PPzQ3Fxca/5vr6+2LVrl1xtpaeno6ioCKmpqRAIBCgqKsKePXsAAMOGDUNYWBgSExNRWVmJH374AcePH+83YPSno6MD2dnZUnebujt37ly/y+RFZzRE5dasWYO//OUvAB7/ZzY1NcXOnTsBAKampqisrMTRo0dx9OhRiEQihIWFAXj8RV27di1KSkowZ84cqS9nZGQk3n77bVhbW+PDDz/E6NGjMXfuXJw8eRLz5s1DaGgoAgMDkZaWhq+//hqAei+dAGD16tV4/fXXERUVJXUZ2HULubv4+Hg0Njbib3/7W692SktLERISwt1d6rJ7927u902bNiEiIgLPPfccTE1N8de//lVqcHig9rtkZ2fj9ddfh56eXq9l3377LaZPn67QWVKfWDe2traMkJ78/f1ZcXExr/tYtmwZS0pK4nUfsiouLmb+/v4DrqOnp8cAsFdffVVq/o0bN9jGjRsH3YeHhwfLz89Xppu8tV9RUcFiY2NZS0sLN++PP/5gABgAFhgYOOD2fXx+xXJfOg3ljE+xWCyVCdnzOp8vPY9BU/0gqtPa2grGmFRmMPB4nGbLli0DbpuTk4OZM2fitdde46VvyrZvZWWFHTt2QF9fn5vXlRnMGFPobqDcl07qTvNWpaCgIDg4OMDT01PqOY6ntR/aIigoCEePHgXw+FJrw4YNGu4Rv7y8vKTygoZa+4qQ64xGWzI+4+PjYWFhAUtLS+zZs4fbnyK0OWv1xIkTcHFxgampKQIDA1FfX4/W1lbuTGj8+PEAgIiIiF4P+F2/fh2enp4QCoVwdnaGRCKROt7Vq1cjMDAQenp6mDNnjsKfnyqIxWLur+WTHmSeWt0vpGQZo4mNjWXr1q2TmnZ0dGSXLl1iZWVlzMrKip08eZJbvmzZMvbcc8+xy5cvs6qqKvbKK6+w8PBwbvmbb77JvvjiC27a1dWVFRQU9Lu8pKSEjR07llVVVbG6ujrm5+fHzp8/P2i/u0gkEqanp9frmNR5DP31o6cpU6awq1evsrq6OrZ06VLuc//555+ZoaEhq6+v59adP38+93tbWxt77rnn2JYtW1hjYyM7fPgws7W1ZW1tbdzxjh49mpWUlLBr166xefPmDdgPdYzRaBNZxmhI/1QyRtMXdWZ8jhgxAtXV1SguLoaBgQGysrLw0ksvccsVvaWp7qxVWUgkErz44oswMTFBaGgozp49CwAYM2YMxowZg4yMDACPb0NOnDiR266wsBBVVVX48MMPIRKJEBwcDJFIhFOnTnHrTJ8+HZMmTcLYsWNx8uRJ3o+FPN1UcntbnRmfEyZMwO7du7F+/XqEhIQgLCwM27Zt427RKXpLU91Zq4NhjCE2NhaHDx/GvXv3wBiTSp5avHgxDh48iBUrVuCLL77ABx98wC0rLy9HU1MTRoyQ/uf99ddfud+70tllUVdXBx8fH+jq6ipxRENH17+9nZ2dhnsyNLW3t8PV1VVqnlryaFSd8RkSEoKQkBCcP38eS5cuhb29PVcDhK9sUFUfw2Byc3Nx8OBBFBUVYcyYMSgpKcE777zDLV+0aBFiY2NRUlKCW7duYcyYMdwye3t7mJubq+xulqmpKY4fP/5U1QxOTk5W2ZPLTxuN1QxWZcZnVlYW1qxZg6amJjg6OkqdaQD8ZYOqOmu1L62trfD19QXw+Mys66e1tRW5ublS69ra2mLGjBlYvHgxvL29pZbNmDEDpqam2LdvH5qamnD16lVMnjwZP/30k7IfAyGK6T5iM9hgcFRUFJe0ExUVxTZt2sRNb926la1atYqbPnDgAGPs8UBqXFwcmzVrFhMKhczHx4fV1tZybd66dYu5u7szkUjEtm/fzlxdXRkAbjD2hx9+YJaWlszKyoqdPXuWPXjwgK1fv57Z2NgwExMT9s4777AHDx5w7a1du5aFhYX12f+MjAyufwDYH3/8oZFj6NmP7j8+Pj6MMcY6OjpYaGgoMzIyYs8//zzbsGEDA8BcXV25/X722Wds+PDhrKKiotexXr9+nc2cOZMJhULm4ODADh48yBhjUsc7ceLEAf+9u9BgMJFHX4PBvGcGa1PGp6K09RgqKirY66+/zvt+KND0pmxmsDarqKhgcXFxms0MJtrj7NmzWLJkiaa7oTS+6v3yXUeYagbLjtdAExQUhL///e+Ij49HYmIin7vijTYeQ1hYGIYPH47U1FQEBgZqujvk/6OawQPofn5DD1WSvshy6dQ1JmRkZMRcXFzYqVOnGGOM+fn5MQBcwuKrr77KAHAJjYGBgVJjVJ9++qnU/HXr1rFXX32VCYVC5uvry42NKdquLGS9dLp27ZrUPFdXV6lEzwsXLkhdRn3yySfM3d1d5n50JxKJuLYfPXrEzM3NWV5eHrd88eLF7P3335e5vZqaGu73R48eMVdXV9bY2Ci1TlhYGEtISJCal5SUpNClE5WJIEprb2/H/PnzsWjRImRnZyM/Px/e3t64du2awvV+h2IdYaoZ3D8aoyFKKywsxO+//46NGzfC2NgYAQEBcHd3x5EjR5Rue6jUEaaawQOjMxqitPLyclhYWEhlDtva2kqNKShqqNQRpprBA6NAQ5Rmb2+P6upqtLe3c8Hm7t27cHd3B6Bc5vRQqiNMNYP7R5dORGkzZsyAjY0Ntm3bhsbGRhw7dgwXLlzgXkimTOb0UKojTDWD+0eBhihNR0cHubm5KCwshI2NDRISEnD8+HE4ODgAeFzvt6ysDNbW1rhz5w5X7zcvLw8AEBoaitTUVCxZsgQrV66UarurjrCjoyPMzMx61RGWt10+6wivXr0ap06dQk1NjdR81k/N4MjIyD7b6aoZ/Pnnn2PYsGEQCASYMWOG1DqbNm3C6NGj8dxzz+Gdd97ps2Zwf+13oZrBRKtoKjNYUxnZVDNY9TWDaYyGEAX0V4L1SaoZ3F1XZrCiKNAQrfQk1xF+GmsGU6AhWkksFquliiFRDxoMJoTwjgINIYR3AtZthMfOzg4LFy7UZH+IFvrnP/8JZ2dnueoMD2X37t3D5cuXMXv2bE13ZUiqqKhAR0dH91KoEqlAk5OT028KNSHA40QyJyenp6Z+MFGMvb199/8jEqnBYG0bqSbap6SkBJMnT6YzXyIXGqMhhPCOAg0hhHcUaAghvKNAQwjhHQUaQgjvKNAQQnhHgYYQwjsKNIQQ3lGgIYTwjgINIYR3FGgIIbyjQEMI4R0FGkII7yjQEEJ4R4GGEMI7CjSEEN5RoCGE8I4CDSGEdxRoCCG8o0BDCOEdBRpCCO+kXrdCSF8+/vhjSCQSAI/f2WNoaAgTExMIBAIsW7YMgYGBGu4h0XISevc2GZRIJMK//vUvPHz4UGq+UCjE5s2bNdQrMpTQGQ0ZVEVFBcaNG4e6ujqp+SNHjkRFRQUEAoGGekaGCAmN0ZBBWVtbY9SoUVLzhg8fjiVLllCQITKhQENk8t5778HQ0JCbNjExwdKlSzXYIzKU0KUTkUltbS0cHBzQ0NAAABg1ahRu376t2U6RoYIunYhszMzM4OrqCgDQ0dFBaGiohntEhhIKNERm7733HoyMjCAUChEcHKzp7pAhhC6diMwePHgAS0tL2Nvb49q1a5ruDhk6lM+jOXz4ML777jtVdIZogc7OTjQ1NcHY2LjP5SYmJtDT00NAQICae8afxsZGGBgYYMQISivrS3R0NKZOnapUG0p/sj/99BPc3Nwwa9YsZZsiWqCqqgobNmxAQkJCn8s9PDzw/PPP45lnnlFvx3j00Ucfwc/PD+PHj9d0V7ROSkoKysrKNB9oAOD5559XuiNEO5SVlcHIyKjff88n8d/Z3Nwc48ePfyKPTVmZmZkqaYcGgwkhvKNAQ4iMSktL8fHHH2u6G0qprKxEfHw8Wltb1bpfCjREaSEhITh+/Lja9ufl5YVDhw6pbX8AUF9fj+DgYERFRQF4PGiekpICR0dHmJqaws/PD1VVVYO2wxhDeno6xo4dCwMDA7i5ueHEiRNS67S0tODdd9+FUCiEnZ0dvvjiC7n6OmLECAgEAqmfuXPnAgCsrKwwadIkrF69Wq42lUWBhijt0KFD8PHx0XQ3eJWSkoK5c+fC3NwcAHDp0iUkJSUhJycHpaWlaGlpkenLe+fOHaSkpCA/Px81NTUIDg7G22+/jfLycm6dzZs349dff0VpaSkOHz6M999/H5cvX5a5r76+vmCMcT/bt2+Xuku4YMECFBUV4erVq3J8AsqhQEOUsmbNGggEAsTExEhNR0ZGwsfHByKRCP7+/nj06BEAICgoiFvf09MTIpEICxYs4J4M9/f3h0Ag4M5YPD09IRAIcPr0aW773NxcLF26FAKBAKmpqWo5zm+++QbTpk2TmhceHo5x48bBwsICc+bMwY0bNwZtx8HBAefPn8eoUaNgaGiIdevWQUdHB1euXAHw+Ezp888/x8aNG2FtbY1Zs2bBx8cHBw4ckLmvaWlp3O+dnZ04evQoFi9eLLWOh4eHygZ6ZUGJA0Qp+/btg76+Pjo6OqSmMzMzkZ2djf379+Pll19GQUEB5s2bB7FYDJFIhOzsbGRnZ8PS0hIBAQFYv3490tLSkJWVBS8vL679M2fOwM3NjZsWi8VoamqCv78/QkJC1HacpaWlGDlyJDft5uYGNzc3tLW1IS8vD7t371bosYyGhgYwxjBhwgQAj9MLampq4OzszK3j4uKCgoICmdvsnnqQl5eHadOmQSQSSa1jZWWF0tJSufurKDqjIbx45ZVX4OzsDDs7O0yaNAk3b96UWu7r64vx48fD0tIS0dHREIvFSu8zJiYGy5cvV7qdnh4+fIjm5mapp9e77N27FxEREVi+fHm/uUcD2blzJxISEmBpaQkAqK6uBgCphEljY2P88ccfCvU9NTUVERERveYLhULcv39foTYVQWc0hBddYxkAYGBggPb29n6XW1tbo7GxEc3NzRAKhQrvs7OzE3w8UaOjowOhUIgHDx70uTwjIwOenp5yt3vw4EHU1tZi27Zt3DwLCwsAj890us5CGhoa8Oyzz8rdfllZGerr6+Hi4tJrWXNzs1qTLinQEI3ofoemoqKCe1gTAHR1ddHS0sIt7/or36W/YlvJyck89PQxJyenPu8qxcXFKdTel19+iZKSkl5jTCNHjoS5uTmuXLkCGxsbAI8HnseNGyf3PtLS0hAeHt7nssrKSjg5OcnfcQXRpRPRiBMnTuDSpUu4d+8ekpOTERQUxC1zdHREXl4empqacOTIETQ2Nkpta2Zmhlu3buH777/HokWLuPl8XToBgJ+fH4qLi3vN9/X1xa5du+RqKz09HUVFRUhNTYVAIEBRURH27NkDABg2bBjCwsKQmJiIyspK/PDDDzh+/Hi/AaM/HR0dyM7O7veZtHPnzqn1eTU6oyFKWbNmDf7yl78AePyf29TUFDt37gQAmJqaorKyEkePHsXRo0chEokQFhYG4PEXd+3atSgpKcGcOXOkvqyRkZF4++23YW1tjQ8//BCjR4/G3LlzcfLkScybNw+hoaEIDAxEWloavv76a247vi6dAGD16tV4/fXXERUVJXXZ13ULubv4+Hg0Njbib3/7W692SktLERISwt1d6rJ7927u902bNiEiIgLPPfccTE1N8de//lVqcHig9rtkZ2fj9ddfh56eXq9l3377LaZPn67QWZLCmJLWrl3Ljh49qmwzREv89ttvbMqUKbzuY9myZSwpKYnXfcjD39+fFRcXD7rejRs32MaNGwddz8PDg+Xn56uiaypvv6KigsXGxrKWlhaZ1lfR97uYzmgIkZGTkxO2bNky4Do5OTmYOXMmXnvtNV76oGz7VlZW2LFjh4p7NTi1jdGcOnUKM2bMgKGhIaysrODl5YV//OMf6Ozs5Napq6vDjh07MHr06F6DZGKxWCqlWk9PDy+88AI++OCDXq8BGYiy6d2yHgtf1PEZ8SkoKAh///vfER8fj8TERE13R+W8vLywdevWIds+X9QSaMRiMQIDAxEREYG7d+/i5s2bXM2Tf//739x6BQUFeOONN2Bra9urjaCgIEgkEujp6YExhsrKSnz66ac4c+YMJk+eLHNOgLLp3bIeC1/U8RnxSSwWc+MaGzZs0HR3iLooe/E12DVcW1sbs7S0ZPv27ZO5TQ8PD/bpp5/2mi+RSJienp7UvLq6OmZtbc1iYmIGbffRo0fM3Nyc5eXlcfMWL17M3n//fZn6Jc+xXL9+nc2cOZMZGRkxFxcXdurUKcYYY1FRUQwAW7VqFfP29mZCoZD5+fmxjo4O1tLSwgAwAOxPf/oTY4yxFStWMADs1VdflWqfr89IHWM02kbWMZqnkarGaHg/o/nPf/6De/fu4a233uKlfRMTE/j7+/d6ArYv/aV3y/pwmazH0t7ejvnz58PDwwPl5eXYsGEDvL29cfv2bezbtw+xsbE4efIkEhMT8fPPP+PcuXMoKCiAvr4+bty4AaFQyN1KTU1NxVtvvYUzZ87I1Me+yPMZEcIH3geDu1Knuz8nomr29vYypWjLkt4dExODhoYGqQfTush6LIWFhfj999+xceNG6OrqIiAgAHv37sWRI0fw4YcfAvi/FH0AUin6Tk5OmDBhAjIyMrBixQqcO3eu18N8ipD1MwKA1tZWSCQSpfc5VNTW1nIPNRJp9+7dU0k7vAearmc4qqqq4OjoyMs+fvvtN24/A5ElvXugXAxZj6W8vBwWFhbQ1dXl5tna2kqVAhgoRT80NBSffvopVqxYgfT0dJUUW5L1MwIef/H4zLLVNrdv30ZGRobUvwl57JdffoG3t7fS7fAeaCZOnIiRI0fiu+++44oGqVJ9fT2ysrJkes+QLOndA33BZD0We3t7VFdXo729nQs2d+/ehbu7u0zHFBAQgNWrV6OkpAQNDQ1cXxUlz2cEPH72SJ0lBDQtICBAJZX+n0TR0dEqaYf3MRpdXV3s378fmzdvxpEjR1BXV4empibk5OTA3t4ely5dUqjduro6fP/995gzZw6MjY1leuZElvTugdLYZT2WGTNmwMbGBtu2bUNjYyOOHTuGCxcu9KoJ0h+hUIiFCxdi8eLF8Pf3l2mbvijyGRHCC3WNSufl5bGpU6cyfX19ZmJiwmbPns0KCwul1vnuu++4uy4AmImJCbcsIyNDapmuri57/vnnWUxMDKutrZW5vw8ePGB//vOfmaGhIbOxsWEHDx7sdTxhYWFKH8vPP//MZs6cyUQiEXN2duYyOTdt2sQdw9atW9mqVau46QMHDnDbFxcXMwsLC9be3q7Wz4juOpHuVHXXiR5BIFIo0PRP1kcQtFlFRQWLi4tT+yMI9PQ2UTs+iovzXbBcVcXJgYGzu4HHdYXfeOMNGBkZwdraWuHExsuXL0NfXx9fffUVN4+Kk6tIz+rvXT+EKENVxcmBgbO7gcdPrwuFQpSXlyM/Px+pqalyD863tbUhKSkJo0aN6rWMipOrAOtW/b37D1GdX375BbNmzYKxsTFcXV2l6tkqUlx8KBQsV1VxcuDxXS5XV9d+l1+9ehWLFy+GiYkJXFxcMG3aNPz3v/+Vq7+JiYnYtGkTDAwM+lxOxcmJVuvKel60aBGys7ORn58Pb29vXLt2DQ4ODgoVF4+IiND6guV8FSfvS1cR99mzZ6OsrAznz59HbGyszNsXFBTA2dkZY8aM6XcdKk5OtFr3rGdjY2MEBATA3d0dR44cUbptVRcsV1XFPT6Lk/clKSkJ1dXVMDU1xcSJE7Fu3Tp4eHjItG1NTQ3Onz+PhQsXDrieuouTU6AhcpEl61lR/RUsV5SqKu7JUpx88+bN0NHRUXpfHR0dePXVVzF9+nQ0Njbi+vXryMzMxCeffCLT9omJifjoo4+4scmLFy8iODgYAoFA6jW46i5OToGGyKV71nOXu3fvws7OjptWtLi4qguWJycny/XitYEMVJxckTcg9Ke0tBQ//fQTVq1aBZFIBAcHBwQEBCArK0um7ffu3Ss1Nunq6or09HQwxqCvr8+tR8XJiVaTJetZ0eLiqi5Yrspi5aosTj4Qe3t7iEQi7N+/H01NTbhz5w4yMzPx4osvqmwfgPqLk1OgIXLR0dFBbm4uCgsLYWNjg4SEBBw/fhwODg7cOpGRkSgrK4O1tTXu3LnDFRfPy8sD8Pih0dTUVCxZsgQrV67ktusqWO7o6AgzM7NeBcvlbVOVxcpXr16NU6dOoaamRmp+X3c14+PjERkZ2W9bOTk5EAgEOHfuHN577z2Ymppyy4RCIb799lucPHkSI0eOxEsvvQRHR0ep4uWDtQ8AP/74o9Sl0/Tp07llVJycaJymMoM1WbCcipP3j4qTE6JmVJxccRRoiMYFBQXh6NGjAB7fdRnKtYS9vLykcn6GWvt8oUBDNE4sFiudM0O0Gw0GE0J4R4GGEMI7lVw6bdiwAXv37lVFU0TDOjo6UFFR0W9Zy/b2dgwbNgwjRjw5V90VFRVYuXKlVEIbeezOnTuYMmWK0u0IGFMu0aCurq5X8hR5cm3duhXu7u5DckCSKMbCwqLfp8BlJFH6z5KpqalUwhF5shkZGcHc3Bz29vaa7goZQmiMhhDCOwo0hBDeUaAhhPCOAg0hhHcUaAghvKNAQwjhHQUaQgjvKNAQQnhHgYYQwjsKNIQQ3lGgIYTwjgINIYR3FGgIIbyjQEMI4R0FGkII7yjQEEJ4R4GGEMI7CjSEEN5RoCGE8I4CDSGEdxRoCCG8U/p1K+TJt3TpUuTk5AAAHj58iGHDhmH48OEQCATYsmULIiIiNNxDouUkdEZDBuXp6YnW1lZUV1ejvr4etbW1qK6uRkdHB2bNmqXp7pEhgAINGdTbb7+NYcN6/1exsLDACy+8oIEekaGGAg0ZlJGRESZNmiQ1T09PD2FhYRrqERlqKNAQmaxcuVLqjaSGhoZYsmSJBntEhhIKNEQmb775ptT0qFGjYGtrq6HekKGGAg2Ria6uLubOnQvg8dnMe++9p+EekaGEAg2R2fLly2FmZgYdHR34+flpujtkCKFAQ2Q2c+ZMPHr0CC4uLjA3N9d0d8gQonTC3pYtW5CWlqaq/hANY4yhtbUVBgYGfS6vq6uDnp5ev8uHotbWVujo6MK9hj0AACAASURBVGD48OGa7opWSk1NhZeXlzJNSEYo24m6ujokJydj4cKFyjZFtEBZWRkWLlwIiUTS5/KLFy/CyckJQqFQzT3jT0BAAKKjozF16lRNd0XrREdH48GDB0q3o3SgIU8XV1dXTXeBDEE0RkMI4R0FGkJkVFpaio8//ljT3VBKZWUl4uPj0draqtb9UqAhSgsJCcHx48fVtj8vLy8cOnRIbfsDgPr6egQHByMqKgoA0NnZiZSUFDg6OsLU1BR+fn6oqqqSqa26ujrs2LEDo0ePRmpqaq/ld+7cwRtvvAEjIyNYW1tjw4YNCvX58uXL0NfXx1dffcXNs7KywqRJk7B69WqF2lQUBRqitEOHDsHHx0fT3eBVSkoK5s6dy93Wv3TpEpKSkpCTk4PS0lK0tLTI/OUtKCjAG2+80W9mdWRkJIRCIcrLy5Gfn4/U1FRkZmbK1d+2tjYkJSVh1KhRvZYtWLAARUVFuHr1qlxtKoMCDVHKmjVrIBAIEBMTIzUdGRkJHx8fiEQi+Pv749GjRwCAoKAgbn1PT0+IRCIsWLAAdXV1AAB/f38IBALujMXT0xMCgQCnT5/mts/NzcXSpUshEAj6PCPgwzfffINp06ZJzQsPD8e4ceNgYWGBOXPm4MaNGzK1FRAQMOCg+tWrV7F48WKYmJjAxcUF06ZNw3//+1+5+puYmIhNmzb1m4bg4eEhd/BSBt11IkrZt28f9PX10dHRITWdmZmJ7Oxs7N+/Hy+//DIKCgowb948iMViiEQiZGdnIzs7G5aWlggICMD69euRlpaGrKwsqZyNM2fOwM3NjZsWi8VoamqCv78/QkJC1HacpaWlGDlyJDft5uYGNzc3tLW1IS8vD7t370ZoaKhK9tX1Oc2ePRtlZWU4f/48YmNjZd6+oKAAzs7OGDNmTL/rWFlZobS0VBXdlQmd0RBevPLKK3B2doadnR0mTZqEmzdvSi339fXF+PHjYWlpiejoaIjFYqX3GRMTg+XLlyvdTk8PHz5Ec3MzDA0Ney3bu3cvIiIisHz5ciQkJKhkf0lJSaiuroapqSkmTpyIdevWwcPDQ6Zta2pqcP78+UHz2oRCIe7fv6+K7sqEAg3hRfdHFAwMDNDe3t7vcmtrazQ2NqK5uVmpfXZ2doKPyrQ6OjoQCoX9Jq5lZGRg8+bN0NHRUXpfHR0dePXVVzF9+nQ0Njbi+vXryMzMxCeffCLT9omJifjoo48gEAggEAhw8eJFBAcHQyAQSN1pam5uxjPPPKN0f2VFgYZoRPc7NBUVFTAyMuKyjXV1ddHS0sItr66ultpWIBD02WZycjIOHDjAQ28BJyenPu8qxcXFwdPTU2X7KS0txU8//YRVq1ZBJBLBwcEBAQEByMrKkmn7vXv3gjHG/bi6uiI9PR2MMejr63PrVVZWwsnJSWX9HgwFGqIRJ06cwKVLl3Dv3j0kJycjKCiIW+bo6Ii8vDw0NTXhyJEjaGxslNrWzMwMt27dwvfff49FixZx8/m6dAIAPz8/FBcX95rv6+uLXbt2qWw/9vb2EIlE2L9/P5qamnDnzh1kZmbixRdfVNk+AODcuXMICAhQaZsDYkpau3YtO3r0qLLNEC3x22+/sSlTpsi8flRUFAPAALCoqCi2adMmbnrr1q1s1apV3PSBAwcYY4wtW7aMxcXFsVmzZjGhUMh8fHxYbW0t1+atW7eYu7s7E4lEbPv27czV1ZUBYCdPnmSMMfbDDz8wS0tLZmVlxc6ePcttt3btWhYWFib3Mfv7+7Pi4uIB16mrq2OTJ09m1dXVUvO9vb3Zjh07pObFxcWxVatW9dvWd999x30mAJiJiYnU8oKCAvbSSy8xQ0NDZmFhwYKCgqT2O1j7jDEmkUik9uHh4cEtO3bsGAsPDx9w+y4q+n4XU6AhUuQNNIpYtmwZS0pK4nUf8pAl0DDG2I0bN9jGjRsHXc/Dw4Pl5+eromsqb7+iooLFxsaylpYWmdZXVaBR26XTqVOnMGPGDBgaGsLKygpeXl74xz/+gc7OTm6dgTImxWIxN8AlEAigp6eHF154AR988AGXgyGLwbIyVXUsfFHHZ0T65uTkhC1btgy4Tk5ODmbOnInXXnuNlz4o276VlRV27NghNV6jFsqGKlkiXkZGBjM1NWVfffUVu3//PmtubmYSiYS5u7sziUTCrff111+zn376iXl4eLBPP/20VzsSiYTp6ekxxhi7f/8+O336NHvppZfYCy+8wGpqamTq72D7GIysx8IXvj8jvs9oAgMDpS6ttIGsZzRPoyFz6dTW1sYsLS3Zvn37ZG5Tli9Rl7q6OmZtbc1iYmJk7/QA+xiIPMdy/fp1NnPmTGZkZMRcXFzYqVOnGGP/N6axatUq5u3tzYRCIfPz82MdHR2spaWF+xL+6U9/YowxtmLFCgaAvfrqqzL1X9nPSB2XTtqGAk3/hsyl03/+8x/cu3cPb731Fi/tm5iYwN/fHydOnOCl/e5kPZb29nbMnz8fHh4eKC8vx4YNG+Dt7Y3bt29j3759iI2NxcmTJ5GYmIiff/4Z586dQ0FBAfT19XHjxg0IhULuDkdqaireeustnDlzRuF+q/MzIqQvvAeaP/74AwCk0rdVzd7entuPsga6RSrrsRQWFuL333/Hxo0bYWxsjICAALi7u+PIkSPcOv1lzjo5OWHChAnIyMgA8Pg2ZM9nbBShys+IEHnx/qyTpaUlgMcJWo6Ojrzs47fffuP2o6yBsktlPZby8nJYWFhAV1eXm2dra4vy8nJueqDM2dDQUHz66adYsWIF0tPTVVIDRZ7PqLa2FsnJyUrvc6i4efMmMjIy+i1f+jS7fPkypkyZonQ7vJ/RTJw4ESNHjsR3333HS/v19fXIysrC/PnzVdLeQNmlsh6Lvb09qqurpYLH3bt3YWdnJ1MfAgICcO3aNZSUlKChoQE2NjayH0AfVP0ZESIv3s9odHV1sX//foSHh+PZZ5/F/PnzMWLECJw5cwbvvfcecnNz4eLiIne7dXV1+N///V/ExsbC2NgYcXFxKulvTEwMGhoa+nyzg6zHMmPGDNjY2GDbtm2IiYlBQUEBLly4IHXpNBChUIiFCxdi8eLF2L17t8LHouhnZGZmhujoaIX3O9RIJBIsWrSIipP3oftZuFLUNSqdl5fHpk6dyvT19ZmJiQmbPXs2KywslFpnoIzJjIwMqWW6urrs+eefZzExMVJZpYMZLCtTluxSWY7l559/ZjNnzmQikYg5OztzCVayZM4yxlhxcTGzsLBg7e3tav2M6K4T6U5Vd52Ufq9TdHQ0pkyZQq9beUIM9rqVJxG9bqV/Kvp+S+ihSkIUNBSKlWuqGHlPT1yg6Z6C3/2HaA8+iouru2C5KouVA+C2NTExQUhIiEKPjGhTMfKenrhAw7rV4uj+Q4gqqbJY+WeffYa0tDRkZ2ejoqIClpaWUsFCFtpWjLynJy7QEP798ssvmDVrFoyNjeHq6oqCggJumSLFxYdiwXJVFivfsWMHdu7cCRcXFxgaGmLXrl2IjIyUqz/aVoy8JypOTuTS9XjFokWLkJ2djfz8fHh7e+PatWtwcHBQqLh4RETEkCtYrqpi5b///jtu376NW7duwdbWFu3t7fD390dycnK/QaMnbSxG3hOd0RC5yPJ4haJUXbB8KBQr73os5PTp07h48SJKSkpw9uxZbN++Xaa+aGsx8p4o0BC5yPJ4haJUXbB8KBQrNzExAQC8//77sLCwgKOjI1asWIGTJ0/K1BdtLUbeEwUaIhdZHq9QtLi4qguWD4Vi5ba2tjAwMOBesNdl+PDhMm2vrcXIe6JAQ+TS/fGKxsZGHDt2DBcuXMDixYu5dRQtLq7qguVDoVi5jo4OQkJCsGfPHty7dw83b97EZ599pvJXDKu9GHkPFGiIXHR0dJCbm4vCwkLY2NggISEBx48fh4ODA7dOZGQkysrKYG1tjTt37mD06NGYO3cu8vLyADx+Oj01NRVLlizBypUrue38/Pywdu1aODo6wszMTOoLq0ibfF06AcDq1atx6tQp1NTUSM3vK50iPj5+wLtIO3bswDPPPIPRo0dj+vTp8PLywgcffCDz9gDw448/Sl06TZ8+nVv27bffYvr06Rg3bpw8h6hayj7EQMXJnyyaetZJkwXLFX3WSV3FytVZjLwnVT3rRLe3CVGQOoqVq6oYuaZRoCEaFxQUhKNHjwJ4/ErYDRs2aLhHquPl5SWVA6Tu7bUFBRqicWKxWOmcGaLdaDCYEMI7CjSEEN4pfelkamqK6Ojop6r045OMMYbW1tZ+6xu3tbVh+PDhGDHiybnqbm1tRVFRkcxJck+bWbNmKd2G0hX2yNNl3bp1mDx5MlVUJPKgCnuEEP5RoCGE8I4CDSGEdxRoCCG8o0BDCOEdBRpCCO8o0BBCeEeBhhDCOwo0hBDeUaAhhPCOAg0hhHcUaAghvKNAQwjhHQUaQgjvKNAQQnhHgYYQwjsKNIQQ3lGgIYTwjgINIYR3FGgIIbyjQEMI4d2T884MwpuGhgY8evQIwONXkzQ3N6O2thYAoKenB0NDQ012jwwB9LoVMqiFCxciJycH+vr6ePToEQQCAYYNG4YHDx4gOTkZK1eu1HQXiXaj162QwYWEhEBPTw+1tbVoaGhAfX09amtroa+vD39/f013jwwBFGjIoF577TUIBIJe88eOHQtLS0sN9IgMNRRoyKBGjBgBLy8vqWAjFArpkonIjAINkUl4eDjMzMy46REjRsDX11eDPSJDCQUaIpPp06dj+PDh3PSkSZNgbGyswR6RoYQCDZGJQCBAYGAghg0bBhMTE7psInKh29tEZj/99BNmzpwJxhgqKyuhr6+v6S6RoUHCa8JeRUUFOjo6+NwFUSNzc3Po6+tjwoQJ+OOPPzTdHaJChoaGMDc35619Xs9o7OzsYG9vz1fzhEdlZWWwtrbGiBHSf4vKy8thZGQEExMTDfWMH42NjWhtbcWzzz6r6a6oXVNTE8aOHYvMzEy+dsHvGQ0ASCQSvndBeDB16lR8/fXXvf5Q3L17F1ZWVlIDw0+Cr7/+Gj/++COSk5M13RW1k0gkvB83PetE5GJra6vpLpAhiO46EUJ4R4GGEDmUlpbi448/1nQ3BlVZWYn4+Hi0trZquisAKNAQFQoJCcHx48fVtj8vLy8cOnRIbfurr69HcHAwoqKiAACdnZ1ISUmBo6MjTE1N4efnh6qqKrna7NrexMQEISEhqKurk7tfly9fhr6+Pr766itunpWVFSZNmoTVq1fL3R4fKNAQlTl06BB8fHw03Q3epKSkYO7cudxt4EuXLiEpKQk5OTkoLS1FS0uLXF/szz77DGlpacjOzkZFRQUsLS2lgoUs2trakJSUhFGjRvVatmDBAhQVFeHq1atytckHCjREJdasWQOBQICYmBip6cjISPj4+EAkEsHf358roBUUFMSt7+npCZFIhAULFnB/0f39/SEQCLgzFk9PTwgEApw+fZrbPjc3F0uXLoVAIEBqairvx/jNN99g2rRpUvPCw8Mxbtw4WFhYYM6cObhx44bM7e3YsQM7d+6Ei4sLDA0NsWvXLkRGRsrVp8TERGzatAkGBgZ9Lvfw8ODztrXM6K4TUYl9+/ZBX1+fS9Dsms7MzER2djb279+Pl19+GQUFBZg3bx7EYjFEIhGys7ORnZ0NS0tLBAQEYP369UhLS0NWVha8vLy49s+cOQM3NzduWiwWo6mpCf7+/ggJCVHLMZaWlmLkyJHctJubG9zc3NDW1oa8vDzs3r0boaGhMrX1+++/4/bt27h16xZsbW3R3t4Of39/JCcn9xs0eiooKICzszPGjBnT7zpWVlYoLS2VqT0+0RkN4dUrr7wCZ2dn2NnZYdKkSbh586bUcl9fX4wfPx6WlpaIjo6GWCxWan8xMTFYvny5Um305eHDh2hubu6zbOnevXsRERGB5cuXIyEhQab2ujKrT58+jYsXL6KkpARnz57F9u3bZdq+pqYG58+fx8KFCwdcTygU4v79+zK1yScKNIRX3dPaDQwM0N7e3u9ya2trNDY2orm5WeH9dXZ2go9kdx0dHQiFQjx48KDP5RkZGdi8eTN0dHRkaq8rs/r999+HhYUFHB0dsWLFCpw8eVKm7RMTE/HRRx9BIBBAIBDg4sWLCA4OhkAgkLrT1NzcjGeeeUamNvlEgYZoVPe7NBUVFTAyMoJQKAQA6OrqoqWlhVteXV0ttW1fVf+Sk5Nx4MABXvrq5OTU512luLg4eHp6ytWWra0tDAwMuDGrLrJmXO/duxeMMe7H1dUV6enpYIxJPexaWVkJJycnufrGBwo0RKNOnDiBS5cu4d69e0hOTkZQUBC3zNHREXl5eWhqasKRI0fQ2Ngota2ZmRlu3bqF77//HosWLQLA36UTAPj5+aG4uLjXfF9fX+zatUuutnR0dBASEoI9e/bg3r17uHnzJj777DOV37U7d+4cAgICVNqmQhiPbG1t+Wye8GjKlCnst99+k3n9qKgoBoABYFFRUWzTpk3c9NatW9mqVau46QMHDjDGGFu2bBmLi4tjs2bNYkKhkPn4+LDa2lquzVu3bjF3d3cmEonY9u3bmaurKwPATp48yRhj7IcffmCWlpbMysqKnT17ljHG2Nq1a1lYWJjcx3v06FG2du3aAdepq6tjkydPZtXV1VLzvb292Y4dO3qtHxcXx1atWtVve/X19SwwMJAZGhoya2trtn79etbe3i7z9owxJpFIuM8VAPPw8OCWHTt2jIWHhw+4PWOMFRcXM39//0HXU0KxxgNNZ2cni42NZTY2NkwgEDAA7N133+WzW2oXGBjIALCkpCRNd0Vm8gYaRSxbtkxrPhNZAg1jjN24cYNt3LhRpjY9PDxYfn6+wn1SZvuKigoWGxvLWlpaBl1XHYFG45dO33zzDXJycnDu3Dk8evQIu3fvlmv7vrJD1Z0xKhaLuUG5nj/jx4+HWCzGsmXL5GpTG46L9Obk5IQtW7YMul5OTg5mzpyJ1157TaH9KLu9lZUVduzYoTXFyTSeR3Px4kXMmTMHDg4Omu6KwoKCguDg4ABPT89ez5bMmzdPQ73SbkFBQTh69CgAoKOjAxs2bNBwj1TLy8tLKg9I3dtrG42e0axZswaJiYn4y1/+IpX12d2JEyfg4uICU1NTBAYGor6+nlvWV3Zofxmj169fh6enJ4RCIZydnaXq5AyWxaqMvLy8PucP9eNSllgs5u6YPGlBhvSBzwszWcZoYmNj2bp167jp3bt3S43RTJkyhV29epXV1dWxpUuXSq3LGGNvvvkm++KLLwac19bWxp577jm2ZcsW1tjYyA4fPsxsbW1ZW1ubVD8cHR3ZpUuXWFlZGbOysuIGHWUhkUiYnp4eN93Y2Mj8/Py46Z7jEdp+XOoYo9Emso7RPImeijGawUgkErz44oswMTFBaGgozp49K3cbhYWFqKqqwocffgiRSITg4GCIRCKcOnVKar2BslhluW3a1tbGjc0YGRkNieMiRB00PkYzEMYYYmNjcfjwYdy7dw+MMYWSj8rLy9HU1NSr/u2vv/4qNT1QFqssGad6enrcGE1TU1O/z+Bo03H1p6mpCREREX2m3D+JysvL0dDQoB05J2pWU1MDXV1dXveh1YEmNzcXBw8eRFFREcaMGYOSkhK88847Uuv0lR3ac569vT3Mzc17ZZbKQ96aqiKRCFlZWX0u06bj6o++vj7Cw8OlHiJ8kv3zn//Ef//7X62p36JOV65cwYkTJ3jdh1YHms7OTu6ntbUVubm5vdbpnh164MABZGRk9Jp3+PBhmJqaYt++fQgLC8Nvv/2GpUuX4rPPPpN6InggMTExaGhoQFpa2hN1XP0ZMWIEJk6c+NS8xaKsrAz379/H1KlTNd0Vjeh5ua1yfI4ADTYY3DObdOvWrdz0kiVLWEdHBwsNDWVGRkbs+eefZxs2bGAAmKurK9dGX9mhfc27fv06mzlzJhMKhczBwYEdPHiQa0OWLNaBMk4zMjKksjPT09Ollncl7HW1r03H1R8aDH56PBWZwUQ7UaCRjTyZwnyqqKhgcXFxMmUC90R3ncgTi48s56FcQ5gxhvT0dIwdOxYGBgZwc3Prd9xkKNQI7okCDSEKUmUN4Tt37iAlJQX5+fmoqalBcHAw3n77bZSXl0utN1RqBPdEgYYo7JdffsGsWbNgbGwMV1dXFBQUAFCs3u/TXkPYwcEB58+fx6hRo2BoaIh169ZBR0cHV65ckVpvqNQI7kmr7zoR7dXe3o758+dj0aJFyM7ORn5+Pry9vXHt2jWF6v1GREQ81TWEe2poaABjDBMmTODmDaUawT3RGQ1RSGFhIX7//Xds3LgRxsbGCAgIgLu7O44cOaJUu6quIQzwUwxL1TWEe9q5cycSEhJgaWkJYOjVCO6JAg1RSHl5OSwsLKQySm1tbXuNKchL1TWEAX7qCKu6hnB3Bw8eRG1tLffqGmDo1QjuiQINUYi9vT2qq6ulHme4e/cu7OzsAChW7xdQfQ1hgL86wqqsIdzlyy+/RElJCfbv3y81f6jVCO6JAg1RyIwZM2BjY4Nt27ahsbERx44dw4ULF7B48WIAitX7BVRfQxjgr46wKmsIA0B6ejqKioqQmpoKgUCAoqIi7NmzR642tKZGcA8UaIhCdHR0kJubi8LCQtjY2CAhIQHHjx/nCphFRkairKwM1tbWuHPnDkaPHo25c+dy9XlCQ0ORmpqKJUuWYOXKlVy7fn5+WLt2LRwdHWFmZib1hVW0Tb5ewbJ69WqcOnUKNTU1UvO7zjp6io+P7/dNlKWlpQgJCcHnn3+OYcOGQSAQYMaMGb3W+/HHH6UunaZPn84t+/bbbzF9+nSMGzdOySPjAZ/pgJQZPHRpIjNYkzWE1ZEZrGwN4YHIUyO4J3VkBtPtbUKUoK4awoPpqhGsrSjQEK1ANYSfbBRoiFYQi8UqyZkh2okGgwkhvKNAQwjhHe+XTt1f/0GGjsbGRvzP//yP0pm+Q8Uvv/yCioqKp/L/a88HN/kgYIyHBIP/LyIioleOARkaGhoaIBKJMGyY9EnvnTt3IBKJpB4VeBK0t7ejo6PjqSnG3tPUqVMRHR3NV/MSXgMNefKsW7cOkydPHvThPkK6kdAYDSGEdxRoCCG8o0BDCOEdBRpCCO8o0BBCeEeBhhDCOwo0hBDeUaAhhPCOAg0hhHcUaAghvKNAQwjhHQUaQgjvKNAQQnhHgYYQwjsKNIQQ3lGgIYTwjgINIYR3FGgIIbyjQEMI4R0FGkII7yjQEEJ4R6/EJYM6ffo0amtrATx+/xFjDAKBAMDjl9y7u7trsntkCKDXrZBBvffee/jiiy+gp6cnNb+9vR2HDh1CYGCghnpGhgh6rxMZ3L///W+88cYbuH//vtR8U1NT3L1796l96RqRGb3XiQxu0qRJvc5mAGDGjBkUZIhMKNAQmbzzzjsYMeL/hvRMTU3x3nvvabBHZCihQENkEhoaCmNjY25aIBBgzpw5GuwRGUoo0BCZjB07lgs0AoEAXl5e0NHR0XCvyFBBgYbILCwsDLq6ujAzM8Py5cs13R0yhNBdJyKzsrIy/OlPf4Kenh6qqqowbBj9nSIykagkYa+mpgb//Oc/VdEU0XKmpqYYN24csrKyNN0VogYLFy5USTsqOaORSCR499134eXlpYo+ES128eJF2NjY4Nlnn+217PLlywAAZ2dndXdLY44cOYLFixdruhu8OHDgABobG1XRlGoS9iQSCZKTk5GZmamKThEt1tzcDKFQ2Oey5ORkAEB0dLQ6u6RRdnZ2KC8v13Q3eKHCY6OEPSKf/oIMIQOhQEMI4R0FGkLUoLS0FB9//LFG+1BZWYn4+Hi0traqfd8UaIhGhYSE4Pjx42rbn5eXFw4dOqS2/QFAfX09goODERUVhc7OTqSkpMDR0RGmpqbw8/NDVVWVTO0wxpCeno6xY8fCwMAAbm5uOHHiRJ/rXr58Gfr6+vjqq6+4eVZWVpg0aRJWr16tkuOSBwUaolGHDh2Cj4+PprvBq5SUFMydOxfm5ua4dOkSkpKSkJOTg9LSUrS0tMj8xb9z5w5SUlKQn5+PmpoaBAcH4+233+41YNvW1oakpCSMGjWqVxsLFixAUVERrl69qpJjkxUFGqIxa9asgUAgQExMjNR0ZGQkfHx8IBKJ4O/vj0ePHgEAgoKCuPU9PT0hEomwYMEC1NXVAQD8/f0hEAi4MxZPT08IBAKcPn2a2z43NxdLly6FQCBAamqqWo7zm2++wbRp07jp8PBwjBs3DhYWFpgzZw5u3LghUzsODg44f/48Ro0aBUNDQ6xbtw46Ojq4cuWK1HqJiYnYtGkTDAwM+mzHw8ND7XeIqcIe0Zh9+/ZBX18fHR0dUtOZmZnIzs7G/v378fLLL6OgoADz5s2DWCyGSCRCdnY2srOzYWlpiYCAAKxfvx5paWnIysqSyuU6c+YM3NzcuGmxWIympib4+/sjJCREbcdZWlqKkSNHAgDc3Nzg5uaGtrY25OXlYffu3QgNDVWo3YaGBjDGMGHCBG5eQUEBnJ2dMWbMmH63s7KyQmlpqUL7VBSd0RCt88orr8DZ2Rl2dnaYNGkSbt68KbXc19cX48ePh6WlJaKjoyEWi5XaX0xMDG/Pbj18+BDNzc296vbs3bsXERERWL58ORISEhRqe+fOnUhISIClpSWAxxn658+fHzSbVygU9ipixjcKNETrmJubc78bGBigvb293+XW1tZobGxEc3Ozwvvr7OwEX4/86ejoQCgU4sGDB72WZWRkYPPmzQo9BX/w4EHU1tZyl53A40umjz76CAKBAAKBABcvXkRwcDAEAoHUnabm5mY888wzih2QgijQkCGn+12aiooKGBkZcYmEurq6aGlp4ZZXV1dLbdtVVL275ORkHDhwgKfePi7g3vPOUlxcHDw9QwgsIwAAFzhJREFUPRVq78svv0RJSQn2798vNX/v3r1gjHE/rq6uSE9PB2MM+vr63HqVlZVwcnJSaN+KokBDhpwTJ07g0qVLuHfvHpKTkxEUFMQtc3R0RF5eHpqamnDkyJFez+qYmZnh1q1b+P7777Fo0SIA/F46AYCfnx+Ki4ul5vn6+mLXrl1yt5Weno6ioiKkpqZCIBCgqKgIe/bskauNc+fOISAgQO59K4WpQHFxMfP391dFU2QI++STT9gnn3wi8/pRUVEMAAPAoqKi2KZNm7jprVu3slWrVnHTBw4cYIwxtmzZMhYXF8dmzZrFhEIh8/HxYbW1tVybt27dYu7u7kwkErHt27czV1dXBoCdPHmSMcbYDz/8wCwtLZmVlRU7e/YsY4yxtWvXsrCwMIWO2dbWdtB16urq2OTJk1l1dTU3z9vbm+3YsaPXunFxcWzVqlV9tnPjxg02bNgw7jPp+tm9e7fUehKJRGq5h4cHt+zYsWMsPDxcZccmo+IhGWgmTpzIALDvvvtObfskg5M30Chi2bJlLCkpidd9yEPWL+ONGzfYxo0bB13Pw8OD5efnK9utPlVUVLDY2FjW0tIi0/qqDDRquXQSi8XcAFXPn/Hjx8vd3n/+8x9MnjyZh56qTktLC959910IhULY2dnhiy++kHnbnp+Xnp4eXnjhBXzwwQdczggZWpycnLBly5YB18nJycHMmTPx2muv8dIHKysr7NixQ2q8Rl3UkkcTFBQEBwcHeHp69nrOYt68eerogtpt3rwZv/76K0pLS3Ht2jV4e3vjpZdekqlWS8/Pq7a2Fv/7v/+LuLg4/OMf/4BEIlH7XQNtEBQUhKNHjwIAOjo6sGHDBg33SLW8vLye2JpOGh8MzsvLk2k9iUSC8ePHw9jYuM+8g+vXr8PT0xNCoRDOzs6QSCQABs82BYD4+HhYWFjA0tISe/bskVrWX7sD6ezsxOeff46NGzfC2toas2bNgo+Pj8J3NszMzDB79mycPn0ajY2NSEpK0srj5ptYLObuqDxpQeZJp7FA05WhKYuWlhYsWLAAixYtwt27d2Fra4tr165xy9vb2/Hmm29i9uzZqKqqwvr16xEQEID29nbs27cPsbGxOHnyJBITE/Hzzz/j3LlzKCgoAPD4LYzZ2dm4evUqbty4gR9//BEXLlwYtN2BVFVVoaamRursxcXFRennS0xMTODv7889SKdtx01If9QaaNra2rhxByMjI5m3O3v2LBobG7F+/XoYGRkhPDwcpqam3PLCwkJUVVXhww8/hEgkQnBwMEQiEU6dOsWt01+26YgRI1BdXY3i4mIYGBggKysLL730kszt9qUrd6P7e5CMjY3xxx9/cNOK3lK1t7fn2tG24yakP2p91klPT48bo2lqapL5eZOKigqYm5tLZVBaWVlxv5eXl6OpqUnqTYoA8Ouvv3K/95dtOmHCBOzevRvr169HSEgIwsLCsG3bNujp6cnUbl8sLCwAPH4WRSQScb93r7OraDbqb7/9xqWca9txA8CWLVu4kp5Pg5qaGtjZ2Wm6G7xQUb1gABp8qFIkEslcSd/a2ho1NTV4+PAhF2y6nx3Y29vD3Ny8VxaorEJCQhASEoLz589j6dKlsLe3R1RUlMLtjhw5Eubm5rhy5QpsbGwAAJcuXcK4ceO4dRT5MtbX1yMrKwvBwcEAtO+4AeDjjz+mmsFPCFUGUI0PBsvilVdegZGREXbt2oWmpiYcOnQIlZWV3PIZM2bA1NQU+/btQ1NTE65evYrJkyfjp59+GrTtrKwsrFmzBk1NTXB0dJQ6A1C03WHDhiEsLAyJiYmorKzEDz/8gOPHjyM8PJxbR55Lp7q6Onz//feYM2cOjI2NERcXp5XHTUi/VJKNM0jCXkZGhlSmYnp6utz7OHfuHBs3bhwTCoXsgw8+YJMnT2YAWGZmJmOMsevXr7OZM2cyoVDIHBwc2MGDBxljbNBs0wcPHrD169czGxsbZmJiwt555x324MEDbr/9tTuYBw8esD//+c/M0NCQ2djY9NpuoGzUnp+Xrq4ue/7551lMTIxUFqy2Hbc6Eva0jQqT2rTOU58ZTLQTBZr+yZoZzKeKigoWFxf35GYGE6IKfNX75buOsDprBg+UkU41g4F+H1HQVkOtv0Rz1FkzuHtG+uHDh/H+++9zbxAFqGawVB2N7j/aaqj1V1v88ssvmDVrFoyNjeHq6solECpa73co1BFWV81gWTPSqWYweaK1t7dj/vz5WLRoEbKzs5Gfnw9vb29cu3ZN4Xq/Q6GOsLpqBveXkd4VzLtQzWDyRCssLMTvv/+OjRs3wtjYGAEBAXB3d8eRI0eUbltb6wirs2awLBnpgGZqBtMZDVGb8vJyWFhYQFdXl5tna2urkoS3/uoIK/qucFXVER6sZrCi5Ty7agZv27aNmydLRjqgmZrBFGiI2tjb26O6uhrt7e1csLl79y7c3d0BKFbvtwsfdYRVpb+awYrqqhncczxJlox0gGoGkyfcjBkzYGNjg23btqGxsRHHjh3DhQsXsHjxYgCK1fvtos11hNVVM1iWjHRAMzWDKdAQtdHR0UFubi4KCwthY2ODhIQEHD9+HA4ODgCAyMhIlJWVwdraGnfu3MHo0aMxd+5crmZRaGgoUlNTsWTJEqxcuVKqbT8/P6xduxaOjo4wMzOT+hIr0q4qX8GyevVqnDp1CjU1Ndy8/u5SxsfHIzIyss92SktLERISgs8//xzDhg2DQCDAjBkzpNbZtGkTRo8ejeeeew7vvPMO/vrXv0oNDn/77beYPn16r7Mc3qkk7Y8ygwnTXGawJusIU81gmRTTGA0haqBNNYM1gQINGdKepDrCT3LNYAo0ZEgTi8VK58wQ/tFgMCGEdxRoCCG8U9ml040bN56qWrGkt3/961+a7oLaNTU1PbH/75uamlTWloAx5ZMFKioqkJGRoYr+EC13+vRp2Nra4sUXX9R0V4gaqKj+s0QlgYY8PdatW4fJkydj4cKFmu4KGTokNEZDCOEdBRpCCO8o0BBCeEeBhhDCOwo0/6+9ew+KqnzjAP7dlOtuBC2uyy1pIXKYNtBKKy+DhMUYiaIUVtRKaGR4wQiRQFAhMhwxspHB8kaDoFQwgwribdIkhvmNCY6JoowX5JIkd4KE9/cHw5kWVJZlD2d3eT4zznDOefd93zMLj+e8+5xnCSG8o0BDCOEdBRpCCO8o0BBCeEeBhhDCOwo0hBDeUaAhhPCOAg0hhHcUaAghvKNAQwjhHQUaQgjvKNAQQnhHgYYQwjsKNIQQ3lGgIYTwjgINIYR3FGgIIbyjb0EgQ0pPT8fly5cBAOfPn4dUKsVTTz0FAPD19YWvr6+Q0yP6r4S+e5sMqaamBjt27EBPT4/afktLS7z11lsCzYoYErqiIUO6fv06XnzxRdy7d09tv1QqRX19PcaNGyfQzIiBoO91IkNTKBSYMGGC2j6RSISAgAAKMkQjFGiIRj7++GNYWFhw2zY2Nli2bJmAMyKGhG6diEYaGhrg5uaG5uZmAIBcLsedO3cgEokEnhkxAHTrRDQjk8ng4uICABg3bhyCg4MpyBCNUaAhGluxYgUkEgmsrKygUqmEng4xIHTrRDTW1NQER0dHTJgwAdXV1UJPhxgO4fJoLly4gH379gk1PBnC/fv30dPTAzMzM7X9UqkUDg4OWLt2rUAz4097ezvEYrHQ0+DNhg0bYG1tLcjYggWayspKXLlyBR988IFQUyCPUFJSguvXrz/w/XFxcRn0cbcx+OSTT7Bz506hp8GL2NhYREREjL1AAwBubm54++23hZwCeQSRSDTo/Vm8eDEee8w4l/bWrl1rtL+Pqampgo5vnL8xhDfGGmQIv+i3hpBhqqqqwoYNGwSdQ11dHdavX49//vlH0HloigIN0RmVSoX8/PxRG8/Pzw979+4dtfEAoLm5GcHBwVi9ejV6e3uRlpYGhUIBa2trLFq0CPX19Rr1wxhDZmYmJk+eDAsLC3h6euLIkSNqbTo7O/Hhhx9CLBbD0dERe/bs4Y7J5XJMmzYNq1at0un58YUCDdGZvXv3wt/fX+hp8CotLQ1z586FVCpFeXk5kpOTUVBQgKqqKnR2dmr8h3/jxg2kpaWhqKgIjY2NCA4ORkBAAG7fvs212bhxI65du4aqqirs378fK1euREVFBXd84cKFOHv2LC5duqTz89Q1CjREJ9asWQORSITIyEi17fDwcPj7+0MikWDx4sVcqYmgoCCuvZeXFyQSCRYuXIimpiYAfYvOIpGIu2Lx8vKCSCTC8ePHudcfPnwYS5cuhUgkQnp6+qic508//YRXX32V2162bBnc3d1ha2sLHx8fXL16VaN+nJ2dUVZWhkmTJsHS0hKfffYZTExMcPHiRQBAb28vvv/+e8TFxcHOzg7e3t7w9/fHrl271PqZMWMGDh06pLsT5AnVoyE6sX37dpibm+P+/ftq24cOHUJeXh6+++47vPTSSyguLoavry+ys7MhkUiQl5eHvLw8yGQyBAYGIioqChkZGcjNzYWfnx/X/+nTp+Hp6cltZ2dno62tDYsXLx7VLOWqqipMnDgRAODp6QlPT090dXWhsLAQKSkpCAkJ0arflpYWMMYwdepUAEB9fT0aGxuhVCq5Ns8//zyKi4vVXieXy1FVVaXl2YweuqIhvJo9ezaUSiUcHR0xbdo0XL9+Xe34ggUL8Nxzz0Emk2Ht2rXIzs4e8ZiRkZFYvnz5iPsZ6N9//0V7ezssLS3V9qempiIsLAzLly9HQkKCVn1v2bIFCQkJkMlkAIC7d+8CAKysrLg2VlZW+Ouvv9ReJxaL8ffff2s15miiKxrCK6lUyv1sYWGB7u7uhx63s7NDa2vriDN0e3t7wceTNSYmJhCLxejo6Bh07MCBA/Dy8tKq3927d+PevXtISkri9tna2gLou9KRSCTczwMTJdvb2/Hkk09qNe5ookBDBPXfT2lqa2vx+OOPc0HG1NQUnZ2d3PH+/+X7Pezp8W3btvEw0z6urq6DPlmKjo7Wur99+/ahtLR00BrTxIkTIZVKcfHiRdjb2wMAysvL4e7urtaurq4Orq6uWo8/WujWiQjqyJEjKC8vR0NDA7Zt24agoCDumEKhQGFhIdra2pCVlYXW1la119rY2KC6uhonT57EkiVLuP183ToBwKJFi3Du3Dm1fQsWLMDXX3897L4yMzNx9uxZpKenQyQS4ezZs9i6dSuAvsTI0NBQJCYmoq6uDqdOnUJ+fv6gYmO//fYbAgMDtT+hUUJXNEQn1qxZg2+++QZA3wOZ1tbW2LJlCwDA2toadXV1yMnJQU5ODiQSCUJDQwH0/eFGRESgtLQUPj4+an+w4eHhCAgIgJ2dHWJiYvD0009j7ty5OHr0KHx9fRESEoJ33nkHGRkZOHjwIPc6vm6dAGDVqlV44403sHr1au62jzH2wPHWr1+P1tZW7NixY9CxqqoqqFQq7tOlfikpKdzP8fHxCAsLg4uLC6ytrfHtt9+qLQ7/8ssvmDlz5qCrHL3EBJKTk8MiIiKEGp4MYTTen48++oglJyfzOsZwODg4aNTu6tWrLC4ubsh2M2bMYEVFRSOd1gPV1taydevWsc7OTo3av/zyy+zmzZu8zEUD5+iKhpBhcnV1xaZNmx7ZpqCgAHPmzMHrr7/Oyxzkcjm++uorXvrmg1Gv0fCRoj7cPrOzsyESibh/ZmZmcHNzw+eff84lp41FQUFB+OGHH7B+/XokJiYKPR2d8/Pzw+bNm4Weht4w6kCjD4KCglBSUgIzMzMwxlBXV4edO3fi9OnTmD59ukHkQPAhOzubW9uIjY0VejqEZ3odaK5cuQJvb29YWVnBw8NDLStSmxR1fUh7t7GxwWuvvYbjx4+jtbUVycnJ3LHKykp4eXlBLBZDqVSipKSEOzZUSj/Qt/hoa2sLmUyGrVu3csce1S8ho0Ko1aGhFhu7urqYi4sLi42NZc3NzezgwYPM3NycVVdXc23efPNNtmfPHm7bw8ODFRcXP/Q4Y30LkC4uLqyiooLV19ez2bNns2XLlo2oz6GUlJQwMzOzQftXrlzJ3N3d1c5306ZNrLW1le3fv585ODiwrq4urv26deuYQqFg5eXl7NatW0wul7OjR48yxhgrLS1lkydPZvX19aypqYktWrSIlZWVadTvg4zFxXpNF4MNES0GP8SZM2dw584dxMXFwdTUFIGBgUhNTUVWVhZiYmJG1Hd/2jvQV1UtODgYGRkZWvcXGRmJlpaWYffh5OTEpZSfOXMG9fX1iImJ4b7OJCkpCceOHVN75qc/pR+AWkr/+PHjcffuXZw7dw7z5s1Dbm4uAODEiRMa9fsg7e3tuHXr1rDOyZD19PQY7fn2P4MmFL0NNLdv34atrS1MTU25fQ4ODmqP0WtL12nv2uZt3Lx5k3u25fbt22hra8P48epvybVr19S2H5bSP3XqVKSkpCAqKgoqlQqhoaFISkrSuN8HOXHiBMrLy4d9XoaqpaXFaEt51tbWCjq+3gYaJycn3L17F93d3VywqampwZQpU7g22qao6zrtXZuU9+bmZuTm5iI4OBhA3/lKpdJB4w2HSqWCSqVCWVkZli5dCicnJyiVSq37nT9/Pq/p/PrG0dHRaNevXnnlFUHH19vF4FmzZsHe3h5JSUlobW3Fzz//jPPnz+Pdd9/l2miboq7rtPfhpLw3NTXh5MmT8PHxgZWVFfeczKxZs2BtbY3t27ejra0Nly5dwvTp0/HHH39o1G9ubi7WrFmDtrY2KBQK7spnpP0SohNCrQ5psth4+fJlNmfOHCaRSJhSqRyUZVldXc2mTJnCJBIJ+/LLL5mHhwcDwC2Qnjp1islkMiaXy9mvv/7KGOtbDI6Ojmbe3t5MLBYzf39/du/evRH1GRERwUJDQx94DgcOHGAAuH+mpqbsmWeeYZGRkWrjMsZYZWUlmzNnDhOLxczZ2Znt3r2bOxYfH8/1sXnzZvbpp59y27t27WIdHR0sKiqK2dvbsyeeeIK9//77rKOjY8h+R/L+GBtaDObNOb0ONHzQt7R3fUWBRnOaPpIwErW1tSw6OlrjRw4GEjrQ6O2tEzF++pC5PVK6Klb+XxUVFTA3N8ePP/7I7TO0YuQDjalAY+xp72T06apYeb+uri4kJydj0qRJg44ZUjHygcZUoKG0d90yxszt4dJVsfJ+iYmJiI+Ph4WFxQOPG0ox8oH09uNtot+6u7sxb948LFmyBHl5eSgqKsL8+fPx559/wtnZWavi4mFhYQZXsFyXxcqLi4uhVCrx7LPPPrSNoRQjH2hMXdEQ3flv5raVlRUCAwMxZcoUZGVljbhvXRcsN4Ri5Y2NjSgrKxsyYdBQipEPRIGGaEWIzG1tCVWsfOPGjTAxMdGor8TERHzxxRdcOZELFy4gODgYIpFI7WtvDaUY+UAUaIhW/pu53a+mpgaOjo7ctj5lbg/84jVdeVix8uF+I0Jqaiq3fsgYg4eHBzIzM8EYg7m5OdfOUIqRD0SBhmjFWDO3h0uXxco1YSjFyAeiQEO0YmJigsOHD+PMmTOwt7dHQkIC8vPz4ezszLUJDw/HrVu3YGdnhxs3bnDFxQsLCwEAISEhSE9Px3vvvYcVK1Zwr+svWK5QKGBjYzOoYPlw++S7WPmxY8fQ2NjI7WOPKFYeHh7+yP5+//13tVunmTNncscMqhj5QEKlCo7FzFNDMhYzt/nODB5JsfLhFiMfSOjMYPp4m5ARGo1i5YZWjHwgCjREbwQFBSEnJwdAX6EmY0qq9PPzG7LQmDGjQEP0RnZ29ohzZoh+osVgQgjvKNAQQngn6K1TQUGB0RaDNnQNDQ1oaWkxyJwNbTHGjPZ8r1y5Iuj4IsZ4SjAYQmNjo+AnT8hY8sILL6g9MjKKSgQLNISQMaOE1mgIIbwbD+B/Qk+CEGLUKv8PTDCqD9SxoRgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras as tfk\n",
    "tfk.utils.plot_model(model,\n",
    "    show_shapes=True,\n",
    "#    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=64,\n",
    "#    layer_range=None,\n",
    "#    show_layer_activations=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e025bcb-c14c-40d5-9b08-636ad79b7a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e5692-6e7c-4ad6-a05a-1374ce382a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
